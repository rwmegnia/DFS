#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Sat Feb 12 13:46:56 2022@author: robertmegnia"""from bs4 import BeautifulSoup as BSimport requestsimport pandas as pdimport osfrom datetime import datetimeimport unidecodeimport numpy as npfrom os.path import existsbasedir = os.path.dirname(os.path.abspath(__file__))datadir= f'{basedir}/Experimental/data'# database=pd.read_csv(f'{datadir}/Database/PlayerDatabase.csv')# database.sort_values(by='game_date',inplace=True)#%%def scrapeStartingLineups(game_date):    print(game_date)    soup=BS(requests.get(f'https://rotogrinders.com/lineups/nba?date={game_date}&site=draftkings').content,'html.parser')    # soup=BS(requests.get(f'https://rotogrinders.com/lineups/nba').content,'html.parser')    players=[]    positions=[]    salaries=[]    projections=[]    starter=[]    ownerships=[]    away_teams=[]    home_teams=[]    away_ou=[]    home_ou=[]    away_proj_pts=[]    home_proj_pts=[]    away_moneylines=[]    home_moneylines=[]    teams=[]    opp=[]    proj_pts=[]    ou=[]    spread=[]    moneylines=[]    game_locations=[]    for game in soup.find_all(attrs={'data-role':'lineup-card'}):        away_team=game.find_all(attrs={'class':'blk crd lineup'})[0].find_all(attrs={'class':'shrt'})[0].text        home_team=game.find_all(attrs={'class':'blk crd lineup'})[0].find_all(attrs={'class':'shrt'})[1].text        away_teams.append(away_team)        home_teams.append(home_team)    odds=soup.find_all(attrs={'class':'ou'})    for game_odds in odds:        try:            away_proj=float(game_odds.find_all(attrs={'href':"/nba/odds"})[0].text)            home_proj=float(game_odds.find_all(attrs={'href':"/nba/odds"})[1].text)        except IndexError:            away_proj=np.nan            home_proj=np.nan        away_proj_pts.append(away_proj)        home_proj_pts.append(home_proj)        away_ou.append(away_proj+home_proj)        home_ou.append(away_proj+home_proj)        try:            away_money_line=game_odds.find_all('div')[0].text.split('(')[1]            away_money_line=int(''.join([c for c in away_money_line if (c .isalnum())|(c=='-')]))            home_money_line=game_odds.find_all('div')[2].text.split('(')[1]            home_money_line=int(''.join([c for c in home_money_line if (c .isalnum())|(c=='-')]))        except:            home_money_line=np.nan            away_money_line=np.nan            home_moneylines.append(home_money_line)            away_moneylines.append(away_money_line)    for index,tm in enumerate(away_teams):        away_team_players=soup.find_all(attrs={'blk away-team'})[index]        n=0        for player in away_team_players.find_all(attrs={'class':'player'}):            teams.append(tm)            game_locations.append('away')            opp.append(home_teams[index])            try:                proj_pts.append(away_proj_pts[index])                spread.append((away_proj_pts[index]-home_proj_pts[index])*-1)                ou.append(away_ou[index])                moneylines.append(away_moneylines[index])            except IndexError:                proj_pts.append(np.nan)                spread.append(np.nan)                ou.append(np.nan)                moneylines.append(np.nan)            name=player.find_all(attrs={'class':'pname'})[0].text.split('\n')[1]            position=player.get('data-pos')            try:                salary=float(player.find_all(attrs={'class':'salary'})[0].text.split('$')[1].split('K')[0])*1000            except IndexError:                salary=np.nan                        try:                ownership=float(player.find_all(attrs={'class':'pown'})[0].get('data-pown').split('%')[0])            except ValueError:                ownership=0            try:                rg_proj=float(player.find_all(attrs={'class':'fpts'})[0].text)            except:                rg_proj=np.nan            players.append(name)            positions.append(position)            salaries.append(salary)            projections.append(rg_proj)            ownerships.append(ownership)            if n>4:                starter.append(False)            else:                starter.append(True)            n+=1    for index,tm in enumerate(home_teams):        home_team_players=soup.find_all(attrs={'blk home-team'})[index]        n=0        for player in home_team_players.find_all(attrs={'class':'player'}):            teams.append(tm)            opp.append(away_teams[index])            game_locations.append('home')            try:                proj_pts.append(home_proj_pts[index])                spread.append((home_proj_pts[index]-away_proj_pts[index])*-1)                ou.append(home_ou[index])                moneylines.append(home_moneylines[index])            except IndexError:                proj_pts.append(np.nan)                spread.append(np.nan)                ou.append(np.nan)                moneylines.append(np.nan)            name=player.find_all(attrs={'class':'pname'})[0].text.split('\n')[1]            position=player.get('data-pos')            try:                salary=float(player.find_all(attrs={'class':'salary'})[0].text.split('$')[1].split('K')[0])*1000            except IndexError:                salary=np.nan            try:                ownership=float(player.find_all(attrs={'class':'pown'})[0].get('data-pown').split('%')[0])            except ValueError:                ownership=0            try:                rg_proj=float(player.find_all(attrs={'class':'fpts'})[0].text)            except:                rg_proj=np.nan            players.append(name)            positions.append(position)            salaries.append(salary)            projections.append(rg_proj)            ownerships.append(ownership)            if n>4:                starter.append(False)            else:                starter.append(True)            n+=1    df=pd.DataFrame({'RotoName':players,                     'RotoPosition':positions,                     'Salary':salaries,                     'RG_projection':projections,                     'ownership_proj':ownerships,                     'team_abbreviation':teams,                     'opp':opp,                     'starter':starter,                     'game_location':game_locations})    print(moneylines,spread,ou,spread)    df=df[df.RotoName!=' ']    #     # Remove ending dots and hyphens    ## REFORMAT PLAYER NAMES BY REMOVING NON-ALPHA-NUMERICS    df["first_name"] = df.RotoName.apply(lambda x: x.split(" ")[0])    df["last_name"] = df.RotoName.apply(        lambda x: " ".join(x.split(" ")[1::])    )    # Remove non-alpha numeric characters from first/last names.    df["first_name"] = df.first_name.apply(        lambda x: "".join(c for c in x if c.isalnum())    )    df["last_name"] = df.last_name.apply(        lambda x: "".join(c for c in x if c.isalnum())    )    # Recreate full_name to fit format "Firstname Lastname" with no accents    df["full_name"] = df.apply(        lambda x: ' '.join([x.first_name,x.last_name]),axis=1    )    df["full_name"] = df.full_name.apply(lambda x: x.lower())    df.drop(["first_name", "last_name"], axis=1, inplace=True)    df["full_name"] = df.full_name.apply(        lambda x: x.split(" ")[0][0].upper()        + x.split(" ")[0][1::]        + " "        + x.split(" ")[-1][0].upper()        + x.split(" ")[-1][1::]    )    df["full_name"] = df.full_name.apply(lambda x: unidecode.unidecode(x))    # Create Column to match with RotoGrinders    df["RotoName"] = df.full_name.apply(        lambda x: x.lower().split(" ")[0][0:4] + x.lower().split(" ")[1][0:5]    )    df['game_date']=game_date    df.team_abbreviation.replace({'PHO':'PHX'},inplace=True)    if not exists(f'{datadir}/Database/startingLineups/{game_date}/{game_date}_Lineups.csv'):        os.mkdir(f'{datadir}/Database/startingLineups/{game_date}')        df.to_csv(f'{datadir}/Database/startingLineups/{game_date}/{game_date}_Lineups.csv',index=False)    else:        last_saved=pd.read_csv(f'{datadir}/Database/startingLineups/{game_date}/{game_date}_Lineups.csv')        last_saved=last_saved[~last_saved.team_abbreviation.isin(df.team_abbreviation)]        df=pd.concat([df,last_saved])        df.to_csv(f'{datadir}/Database/startingLineups/{game_date}/{game_date}_Lineups.csv',index=False)    odds_db=pd.read_csv(f'{datadir}/Database/OddsDatabase.csv')    if game_date not in odds_db.game_date.unique():        odds_db=pd.concat([odds_db,df])        odds_db.to_csv(f'{datadir}/Database/OddsDatabase.csv',index=False)    return df